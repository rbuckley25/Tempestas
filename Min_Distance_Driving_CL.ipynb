{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832eda18",
   "metadata": {},
   "source": [
    "# Reinforcement Learning: Min Distance RL with CARLA ENV CL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d54a80",
   "metadata": {},
   "source": [
    "At the recommednation of one of the authors of the paper I will try to adapt the following [tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) to work acheive the same results as in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257b48f",
   "metadata": {},
   "source": [
    "Notes: Pygame only runs on python 3.7, pytorch must be install direclty into the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d2016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import carla\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import gym\n",
    "import gym_carla\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09526aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "connecting to Carla server...\n",
      "Carla server connected!\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "# parameters for the gym_carla environment\n",
    "params = {\n",
    "    'number_of_vehicles': 0,\n",
    "    'number_of_walkers': 0,\n",
    "    'display_size': 256,  # screen size of bird-eye render\n",
    "    'max_past_step': 1,  # the number of past steps to draw\n",
    "    'dt': 0.1,  # time interval between two frames\n",
    "    'discrete': True,  # whether to use discrete control space\n",
    "    'discrete_acc': [2.0],  # discrete value of accelerations\n",
    "    'discrete_steer': [-0.3, 0.0, 0.3],  # discrete value of steering angles\n",
    "    'continuous_accel_range': [-3.0, 3.0],  # continuous acceleration range\n",
    "    'continuous_steer_range': [-0.3, 0.3],  # continuous steering angle range\n",
    "    'ego_vehicle_filter': 'vehicle.lincoln*',  # filter for defining ego vehicle\n",
    "    'port': 2000,  # connection port\n",
    "    'town': 'Town04',  # which town to simulate\n",
    "    'task_mode': 'random',  # mode of the task, [random, roundabout (only for Town03)]\n",
    "    'max_time_episode': 250,  # maximum timesteps per episode\n",
    "    'max_waypt': 12,  # maximum number of waypoints\n",
    "    'obs_range': 32,  # observation range (meter)\n",
    "    'lidar_bin': 0.125,  # bin size of lidar sensor (meter)\n",
    "    'd_behind': 12,  # distance behind the ego vehicle (meter)\n",
    "    'out_lane_thres': 1.8,  # threshold for out of lane\n",
    "    'desired_speed': 5,  # desired speed (m/s)\n",
    "    'max_ego_spawn_times': 20,  # maximum times to spawn ego vehicle\n",
    "    'display_route': True,  # whether to render the desired route\n",
    "    'pixor_size': 64,  # size of the pixor labels\n",
    "    'pixor': False,  # whether to output PIXOR observation\n",
    "    'use_fixed':'E'\n",
    "}\n",
    "\n",
    "# Set gym-carla environment\n",
    "env = gym.make('carla-v0', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d45005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5df687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.lin2 = nn.Linear(9,30)\n",
    "        self.lin3 = nn.Linear(30,50)\n",
    "        self.lin4 = nn.Linear(50,25)\n",
    "        self.lin5 = nn.Linear(25,9)\n",
    "        self.lin6 = nn.Linear(9,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.relu(self.lin3(x))\n",
    "        x = F.relu(self.lin4(x))\n",
    "        x = F.relu(self.lin5(x))\n",
    "        x = F.relu(self.lin6(x))\n",
    "        \n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869cac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 300\n",
    "TARGET_UPDATE = 50\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "\n",
    "test_net = DQN(n_actions).to(device)\n",
    "test_net.load_state_dict(torch.load('./model_params_CL/model_4.best'))\n",
    "#policy_net = DQN(n_actions).to(device)\n",
    "policy_net = test_net\n",
    "target_net = DQN(n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "# Model <= 7\n",
    "#optimizer = optim.RMSprop(policy_net.parameters())\n",
    "\n",
    "#Model 8 & from 2022 \n",
    "optimizer = optim.Adam(policy_net.parameters(),lr=0.005)\n",
    "\n",
    "\n",
    "memory = ReplayMemory(7500)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            #arg max select the idex of the largest value and view changes shape from (1,) to (1,1)\n",
    "            #try test net\n",
    "            return policy_net(state.float()).argmax().view(1,1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18320225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    #reshape state_batch for nn\n",
    "  \n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    \n",
    "    # selects column of output that was selceted \n",
    "    state_action_values = policy_net(torch.reshape(state_batch,(BATCH_SIZE,1,9)).float()).gather(1,action_batch)\n",
    "    \n",
    "    \n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(torch.reshape(non_final_next_states,(list(non_final_next_states.shape)[0]//9,1,9)).float()).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp(-1, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c90a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5880/142952944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Select and perform an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Carla/gym-carla/gym_carla/envs/carla_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Carla/gym-carla/gym_carla/envs/carla_env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;31m# Display birdeye image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0mbirdeye_surface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb_to_display_surface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbirdeye\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbirdeye_surface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Carla/gym-carla/gym_carla/envs/misc.py\u001b[0m in \u001b[0;36mrgb_to_display_surface\u001b[0;34m(rgb, display_size)\u001b[0m\n\u001b[1;32m    245\u001b[0m   \"\"\"\n\u001b[1;32m    246\u001b[0m   \u001b[0msurface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSurface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m   \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdisplay_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m   \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    164\u001b[0m         out = warp(image, tform, output_shape=output_shape, order=order,\n\u001b[1;32m    165\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                    preserve_range=preserve_range)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# n-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    861\u001b[0m                                                   \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                                                   \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                                                   cval=cval))\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "use_fixed_idx = 0\n",
    "env.use_fixed = 'H'\n",
    "levels = ['E','M','H']\n",
    "next_lvl = 100\n",
    "min_overall_loss = 1000\n",
    "for i_episode in range(num_episodes):\n",
    "    rewards = []\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    #ego_dir retirves the distance and angle from vehicle to nearest waypoint\n",
    "    ego_location = env.ego.get_location()\n",
    "    ego_dir = gym_carla.envs.misc.get_lane_dis(env.waypoints,ego_location.x,ego_location.y)\n",
    "    #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "    ego_pos = np.asarray((ego_dir[0],ego_dir[1][0],ego_dir[1][1]),dtype=np.float32)\n",
    "    state = np.concatenate((ego_pos,np.zeros(6)))\n",
    "    state = torch.tensor(state)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    loss = episode_loss = 1000\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _ , reward, done, info  = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        if not done:\n",
    "            \n",
    "            #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "            pos = np.asarray((info['position'][0],info['position'][1][0],info['position'][1][1]))\n",
    "            ang = np.asarray(info['angular_vel'])\n",
    "            acc = np.asarray(info['acceleration'])\n",
    "            steer = np.asarray(info['steer'])\n",
    "            next_state = np.concatenate((pos, ang, acc, steer), axis=None)\n",
    "            next_state = torch.tensor(next_state)\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        loss = optimize_model()\n",
    "        \n",
    "        #if loss is better than previous minimum save mode\n",
    "        if loss is not None and loss < episode_loss:\n",
    "            episode_loss = loss\n",
    "            writer.add_scalar(\"Loss/train\", loss, i_episode)\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "            \n",
    "    # Update the target network\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    len_episode = t+1\n",
    "    writer.add_scalar(\"Lenght/Epoch\", len_episode, i_episode)\n",
    "    \n",
    "    if i_episode > 0 and i_episode % next_lvl == 0:\n",
    "        #saving model after each level\n",
    "        torch.save(target_net.state_dict(), './model_params_CL/model_5_'+levels[use_fixed_idx]+'.final')\n",
    "        print(levels[use_fixed_idx])\n",
    "        use_fixed_idx += 1\n",
    "        env.use_fixed = levels[use_fixed_idx]\n",
    "        steps_done = 0\n",
    "    \n",
    "    #save model if better than previous episode\n",
    "    if episode_loss < min_overall_loss:\n",
    "        min_overall_loss = episode_loss\n",
    "        torch.save(target_net.state_dict(), './model_params_CL/model_5.best')\n",
    "    \n",
    "\n",
    "print('Complete')\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa098d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fa528f",
   "metadata": {},
   "source": [
    "### Visualise Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef6c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (lin2): Linear(in_features=9, out_features=30, bias=True)\n",
       "  (lin3): Linear(in_features=30, out_features=50, bias=True)\n",
       "  (lin4): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (lin5): Linear(in_features=25, out_features=9, bias=True)\n",
       "  (lin6): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net = DQN(n_actions).to(device)\n",
    "test_net.load_state_dict(torch.load('./model_params_CL/model_4.best'))\n",
    "test_net.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6af9bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lin2.weight',\n",
       "              tensor([[-2.3603e+00, -5.4920e-01,  4.0326e-01,  2.9293e-01, -3.5443e-01,\n",
       "                        6.6183e-02, -1.5918e-01,  3.1419e-02,  6.5821e-01],\n",
       "                      [-2.2821e+00,  7.3115e-01,  1.0576e+00, -1.2068e-01, -6.4843e-01,\n",
       "                       -4.2995e-02, -7.3903e-02, -1.3199e-01, -1.4904e-01],\n",
       "                      [-1.8904e+00, -8.6865e-01, -1.2619e-01,  6.8824e-01, -2.2046e-01,\n",
       "                        1.6384e-01, -2.8278e-01, -5.1333e-02, -8.4200e-01],\n",
       "                      [-2.2685e-02,  5.9306e-01, -7.0524e-02,  1.0459e-01, -8.6592e-01,\n",
       "                        2.4361e-03, -4.5457e-01, -1.9476e-01, -1.0519e-01],\n",
       "                      [ 2.9914e+00,  3.1211e-01,  1.8740e-01, -1.0017e-01, -6.9231e-02,\n",
       "                       -2.8261e-02, -1.8122e-01, -3.7208e-02,  2.2318e-02],\n",
       "                      [ 1.5985e+00, -1.3307e+00,  9.9561e-01,  5.5225e-01,  4.2735e-01,\n",
       "                       -1.2502e-01,  4.4278e-02, -3.3751e-01,  1.2225e+00],\n",
       "                      [ 2.4763e+00, -6.0940e-01, -1.0144e-01,  1.4188e-01, -3.6191e-01,\n",
       "                        4.3925e-02, -1.8311e-01, -3.9303e-02, -1.9616e-01],\n",
       "                      [ 2.4632e+00,  3.0555e-01, -3.5374e-01, -5.6027e-02, -2.9621e-01,\n",
       "                       -5.0990e-02,  6.6326e-02, -7.8971e-02,  1.7570e-01],\n",
       "                      [-2.3591e+00,  1.0172e+00, -1.0051e+00,  7.2500e-02, -4.1128e-01,\n",
       "                       -7.7029e-02, -4.9132e-01,  1.4726e-01, -4.7944e-01],\n",
       "                      [ 1.6980e+00, -1.3622e+00,  7.5438e-02,  2.8500e-01,  5.2788e-01,\n",
       "                       -5.8998e-02,  6.4754e-01,  5.9678e-02,  1.8020e-01],\n",
       "                      [-2.1486e+00, -3.2526e-01, -1.4029e+00,  2.0066e-01, -6.2586e-01,\n",
       "                       -8.9084e-02, -2.5811e-02, -2.0164e-01, -4.8560e-01],\n",
       "                      [-2.0759e+00, -1.7461e+00, -7.6648e-01, -6.6382e-01,  5.7326e-02,\n",
       "                        2.0834e-02,  2.6854e-01,  8.6270e-01,  7.3591e-01],\n",
       "                      [ 9.0257e-01, -1.6496e+00,  1.5998e-02,  9.0517e-01,  5.6022e-02,\n",
       "                        1.3632e-02, -8.5772e-02, -7.3572e-01, -5.6545e-01],\n",
       "                      [-2.1992e+00, -1.4751e-01, -5.1628e-01, -7.0463e-02,  1.5611e-01,\n",
       "                        5.4169e-02, -3.5962e-01,  1.6251e-01,  2.1563e-01],\n",
       "                      [ 1.1010e+00,  6.4176e-02, -6.6517e-01, -3.4215e-01,  2.5054e-01,\n",
       "                       -6.6372e-02,  5.5046e-01,  4.2634e-01,  3.1024e-01],\n",
       "                      [ 2.2559e+00,  1.9983e-01, -2.8858e-01,  8.7169e-02,  6.1619e-01,\n",
       "                       -1.4455e-02,  1.4783e-01, -2.3296e-02,  3.3886e-01],\n",
       "                      [-3.7930e-01,  1.0620e+00,  5.4046e-01,  4.9155e-01,  7.1633e-01,\n",
       "                       -7.2813e-03,  5.5552e-01, -4.9005e-01,  1.3654e+00],\n",
       "                      [ 1.6460e+00,  4.6589e-01,  6.8909e-01, -9.6962e-02,  1.1837e-01,\n",
       "                        8.4365e-02,  1.7825e-01,  1.2550e-01,  2.5293e-01],\n",
       "                      [-1.5039e+00, -1.4952e+00, -8.0092e-01,  1.2208e+00, -3.0884e-01,\n",
       "                        2.7173e-02, -1.1095e-01, -6.7512e-01, -9.7845e-01],\n",
       "                      [ 1.2652e+00,  1.8201e+00,  5.5743e-01, -7.6619e-01,  3.2109e-01,\n",
       "                       -1.1469e-01,  6.9959e-03,  6.7351e-01,  1.5812e+00],\n",
       "                      [ 1.5472e+00, -2.4392e-01,  1.5053e+00, -9.4987e-02, -1.0913e+00,\n",
       "                       -6.4422e-02, -5.3966e-01,  8.0272e-02,  4.0063e-01],\n",
       "                      [-3.7398e+00,  1.9841e-01, -1.6982e-01, -8.3599e-02,  9.2329e-02,\n",
       "                        9.7475e-03,  8.1850e-02,  1.0866e-02, -3.4186e-01],\n",
       "                      [-6.1858e-01, -2.7524e+00, -4.5831e-02, -5.2834e-01, -1.3231e-01,\n",
       "                       -4.5363e-03, -5.9907e-01,  9.5446e-02,  1.5291e-01],\n",
       "                      [ 1.7086e+00, -3.9422e-01,  7.2479e-01, -2.1884e-01, -2.3300e-01,\n",
       "                        4.8974e-02, -3.0783e-01,  1.2761e-01, -5.8110e-01],\n",
       "                      [ 9.8964e-01,  1.0745e+00,  1.8427e+00,  2.5996e-01, -2.6159e-01,\n",
       "                        5.6895e-03, -1.4343e-01,  4.0251e-01,  4.2498e-01],\n",
       "                      [-1.3346e+00,  1.0563e+00, -1.6460e-01, -4.2261e-01,  1.3386e-01,\n",
       "                        4.7029e-02, -2.5158e-01, -5.7628e-01,  2.8096e-01],\n",
       "                      [-1.2681e+00,  3.8855e-01,  4.2073e-01,  3.2870e-01,  1.0610e+00,\n",
       "                       -3.1504e-03,  2.4285e-01, -3.7170e-01,  5.5999e-02],\n",
       "                      [-2.7014e+00, -2.1395e+00, -1.1624e+00,  5.3465e-01,  5.0485e-01,\n",
       "                       -4.3402e-02,  9.7951e-02,  3.1950e-02,  1.7486e+00],\n",
       "                      [ 1.4361e+00, -3.7812e-01, -6.2575e-01,  7.4029e-01, -5.2639e-01,\n",
       "                       -1.9510e-02, -3.0690e-01,  1.5414e-01,  6.8380e-01],\n",
       "                      [-2.5863e-01, -8.5895e-01,  1.5055e+00,  6.8171e-01, -4.8874e-01,\n",
       "                       -6.3538e-02, -5.9986e-01, -1.0986e-01, -1.7958e-01]], device='cuda:0')),\n",
       "             ('lin2.bias',\n",
       "              tensor([ 0.8154,  0.6742, -1.5006,  1.1550, -0.4978, -1.1295, -0.3330, -0.4705,\n",
       "                      -0.1069, -1.0157,  0.0750, -1.1529, -0.9464,  0.5341,  0.0827, -0.5291,\n",
       "                       0.7925, -0.6104, -1.4725, -1.3180, -1.4021, -0.6991,  0.2307, -0.7766,\n",
       "                      -0.4800, -0.2607, -0.2523, -0.2175, -0.5392,  0.1895], device='cuda:0')),\n",
       "             ('lin3.weight',\n",
       "              tensor([[ 0.4067,  0.0320, -0.2137,  ...,  0.3146,  0.0245,  0.3592],\n",
       "                      [ 0.0907, -0.3627, -0.0728,  ..., -0.3162, -0.1781, -0.1237],\n",
       "                      [-0.8118, -0.4874,  0.0055,  ..., -0.2378, -0.6541,  0.6070],\n",
       "                      ...,\n",
       "                      [ 0.2493,  0.5504,  0.1106,  ..., -0.7507,  0.4120, -0.4612],\n",
       "                      [-1.0598,  0.0926,  0.4502,  ..., -0.5765,  0.0773, -0.8859],\n",
       "                      [-1.8349, -0.8285, -1.4419,  ..., -1.2350, -0.4928,  0.0850]],\n",
       "                     device='cuda:0')),\n",
       "             ('lin3.bias',\n",
       "              tensor([-0.0818, -0.0194, -0.9885,  0.7178, -0.0348,  0.0079, -0.7636,  0.5187,\n",
       "                       0.7266, -1.0814, -1.7255, -0.2912, -0.5340, -1.3869,  0.5866, -0.1127,\n",
       "                      -0.2280, -0.7064,  0.0750,  0.3027,  0.7149, -0.1677, -0.5753, -0.7526,\n",
       "                      -1.1881,  0.8561,  0.2286,  0.2456, -0.0682, -0.3184, -0.1911, -0.0966,\n",
       "                      -0.2885, -0.1382, -0.8292, -0.7390, -1.2873,  0.1172,  0.8511, -0.1177,\n",
       "                      -0.8762, -0.4113, -0.2691, -1.9401,  0.0759, -0.5070,  0.4649, -0.4411,\n",
       "                      -0.6750, -0.2551], device='cuda:0')),\n",
       "             ('lin4.weight',\n",
       "              tensor([[-0.4173,  0.0429, -0.1603,  ...,  0.0315, -0.1815, -0.1355],\n",
       "                      [ 0.1926,  0.0321, -0.8749,  ...,  0.2362, -1.1640,  0.7972],\n",
       "                      [-0.3774,  0.0142, -0.2194,  ...,  0.0153, -0.6108, -1.0596],\n",
       "                      ...,\n",
       "                      [ 0.1419, -0.0286, -0.3392,  ..., -0.2630,  0.2458,  0.1647],\n",
       "                      [-0.1875,  0.0483, -1.4138,  ...,  0.0849, -1.5885, -0.3535],\n",
       "                      [ 0.1128, -0.0246,  0.0382,  ..., -0.1438, -0.1752, -0.1619]],\n",
       "                     device='cuda:0')),\n",
       "             ('lin4.bias',\n",
       "              tensor([-0.3682, -0.4867,  0.5845,  1.0304, -0.8126,  0.9761,  1.1270, -0.7413,\n",
       "                      -0.5409, -0.1739, -0.7843,  1.0892, -0.3002,  0.5579, -0.5267, -1.2255,\n",
       "                      -0.9176,  0.7457,  0.7797, -0.9049, -1.2256, -0.8281,  0.9702,  0.5490,\n",
       "                       1.2355], device='cuda:0')),\n",
       "             ('lin5.weight',\n",
       "              tensor([[-1.2452e-01,  9.8344e-02, -1.9656e-01, -2.9626e-01,  3.1403e-01,\n",
       "                       -2.9761e-01, -1.2826e-01, -1.2231e-01,  2.0567e-02, -2.3570e-01,\n",
       "                       -3.6678e-01, -3.2487e-01, -8.0550e-02,  6.2303e-02, -2.5351e-01,\n",
       "                       -1.3500e-01, -1.4379e-03, -1.2076e-01, -4.6062e-01, -1.3072e-01,\n",
       "                       -4.6352e-01, -1.1877e-01, -1.2254e-01, -3.2447e-01, -4.2665e-01],\n",
       "                      [ 4.7711e-03, -2.2508e-01,  7.4412e-02,  3.0986e-02, -8.7124e-01,\n",
       "                       -1.5427e+00,  5.0027e-01, -3.6409e-01,  3.3394e-01, -8.8235e-02,\n",
       "                       -4.7231e-01,  2.2565e-01,  3.4823e-01, -1.4343e-01,  9.6317e-02,\n",
       "                       -8.9734e-01, -4.8427e-01, -1.9352e-01, -1.1167e+00, -8.2502e-01,\n",
       "                        2.6736e-01, -8.5021e-01, -1.1122e+00,  4.6682e-01, -4.5131e-01],\n",
       "                      [ 8.7391e-03,  1.5061e-03,  4.9674e-02, -2.2087e-01, -2.6896e-01,\n",
       "                       -2.8951e-01, -4.3811e-01,  4.7147e-02,  3.7946e-02, -8.5438e-02,\n",
       "                       -3.1610e-01, -2.2823e-01, -1.3399e-01, -2.3078e-01, -2.9989e-01,\n",
       "                        3.9919e-02, -7.6922e-02, -3.9265e-01, -2.1289e-01, -1.3913e-01,\n",
       "                       -2.3245e-01, -1.2581e-01, -2.9387e-01, -7.8802e-02, -1.3912e-01],\n",
       "                      [ 2.3780e-01, -5.0558e-01,  2.3982e-01,  2.8385e-01,  2.5569e-02,\n",
       "                        1.5675e-01, -1.4762e-01, -9.5108e-01, -6.4026e-02,  1.0638e-01,\n",
       "                        4.4138e-01,  1.8587e-01, -2.9429e-02,  1.7907e-01, -2.4096e-01,\n",
       "                        6.3998e-01, -4.8867e-01,  5.3044e-02, -1.1275e-01,  3.4296e-01,\n",
       "                       -3.3263e-01,  3.9339e-01,  6.9468e-02, -9.3987e-04, -1.2850e-01],\n",
       "                      [-2.5177e-01,  6.8344e-01,  1.9936e-01, -1.6233e-01, -1.6827e-01,\n",
       "                        1.5126e-01, -6.2228e-02, -5.4401e-03, -2.4570e-01,  7.6373e-02,\n",
       "                        2.5842e-01,  9.1003e-03, -3.1853e-01,  4.5813e-02,  1.4311e-01,\n",
       "                        7.8882e-01, -4.6826e-01, -3.2658e-02,  1.4866e-01,  3.1588e-01,\n",
       "                       -5.9875e-01, -5.8132e-01, -1.3814e-01, -7.0913e-02,  8.2021e-02],\n",
       "                      [ 8.3101e-02, -3.4059e-02, -3.0164e-01,  7.9660e-02, -3.8991e-02,\n",
       "                       -2.2475e-01, -2.1721e-01, -1.9755e-01, -4.4361e-01, -2.6978e-02,\n",
       "                       -5.1318e-02, -4.1565e-01,  1.0736e-02, -5.2594e-01, -4.5894e-01,\n",
       "                       -2.7473e-02, -3.7570e-02,  1.3601e-01, -4.2458e-01, -1.6411e-02,\n",
       "                       -4.7374e-01,  2.9099e-02, -7.5187e-02, -1.1870e-01, -3.6882e-01],\n",
       "                      [ 5.6224e-02,  5.9948e-01, -5.4274e-01, -1.5034e-01,  5.7980e-01,\n",
       "                       -6.6000e-01, -4.0518e-01,  3.1305e-01,  3.4118e-01,  7.7349e-02,\n",
       "                       -1.3226e-01,  7.7502e-01, -6.7428e-02, -7.7904e-01,  4.6297e-01,\n",
       "                        1.0058e+00,  4.4754e-01, -2.7058e-01, -1.5731e-02, -2.5746e-01,\n",
       "                        6.5647e-01, -1.2675e+00, -5.7009e-01,  4.4027e-01, -9.4850e-01],\n",
       "                      [ 2.1551e-01,  1.7355e-01, -9.7484e-02,  4.1406e-01,  1.0300e-01,\n",
       "                       -8.8885e-02,  1.1465e-01, -3.1164e-01, -1.4317e-01, -2.1634e-01,\n",
       "                       -2.4975e+00,  1.1789e-01, -2.5858e-01, -7.8955e-02, -6.3524e-02,\n",
       "                       -1.1413e+00, -4.5535e-01,  1.2622e-01, -1.7770e-01, -6.2398e-01,\n",
       "                       -2.1975e-01, -3.5564e-01,  2.2924e-01,  8.3960e-02,  1.5150e-01],\n",
       "                      [-4.7817e-02,  1.0317e-01,  6.0717e-02, -3.3427e-02, -2.3349e-01,\n",
       "                       -3.1769e-02,  3.5406e-01,  9.8295e-02, -1.6565e-01, -7.8057e-02,\n",
       "                       -2.8628e-01,  1.5178e-01,  1.1024e-01,  1.5678e-01, -4.4703e-01,\n",
       "                       -4.3866e-01,  5.2485e-01, -2.1827e-01,  2.3372e-01, -6.2488e-01,\n",
       "                        2.1065e-01, -1.0156e+00,  9.0762e-02,  2.2438e-01,  2.5788e-01]],\n",
       "                     device='cuda:0')),\n",
       "             ('lin5.bias',\n",
       "              tensor([-0.3322, -1.0724, -0.3455,  0.9629,  0.9748, -0.2414, -0.3013,  1.1073,\n",
       "                       0.8540], device='cuda:0')),\n",
       "             ('lin6.weight',\n",
       "              tensor([[-0.0674, -0.6200, -0.0800,  0.5376,  0.1211,  0.1079, -0.4952,  0.5903,\n",
       "                       -0.0209],\n",
       "                      [ 0.0885, -0.1208, -0.1956,  0.0136,  0.7675, -0.2041, -0.5048,  0.7612,\n",
       "                        0.1672],\n",
       "                      [ 0.0807, -0.9711,  0.1071,  0.1289,  0.3194, -0.3431, -0.5476,  0.3048,\n",
       "                        0.6880]], device='cuda:0')),\n",
       "             ('lin6.bias', tensor([1.0580, 0.4069, 0.6676], device='cuda:0'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21657e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5\n",
      "-7.274427213016729\n",
      "-5.442185202595971\n",
      "-5.795690578570656\n",
      "-6.789813889991775\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 5\n",
    "env.use_fixed = 'H'\n",
    "use_fixed_idx = 0\n",
    "levels = ['E','M','H']\n",
    "next_lvl = 4\n",
    "min_overall_loss = 1000\n",
    "for i_episode in range(num_episodes):\n",
    "    rewards = 0\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    #ego_dir retirves the distance and angle from vehicle to nearest waypoint\n",
    "    ego_location = env.ego.get_location()\n",
    "    ego_dir = gym_carla.envs.misc.get_lane_dis(env.waypoints,ego_location.x,ego_location.y)\n",
    "    #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "    ego_pos = np.asarray((ego_dir[0],ego_dir[1][0],ego_dir[1][1]),dtype=np.float32)\n",
    "    state = np.concatenate((ego_pos,np.zeros(6)))\n",
    "    state = torch.tensor(state)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    loss = episode_loss = 1000\n",
    "    for t in count():\n",
    "        # Select and perform an actionii#\n",
    "        with torch.no_grad():\n",
    "            action = test_net(state.float()).argmax().view(1,1)\n",
    "        _ , reward, done, info  = env.step(action.item())\n",
    "        rewards += reward\n",
    "            \n",
    "        #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "        pos = np.asarray((info['position'][0],info['position'][1][0],info['position'][1][1]))\n",
    "        ang = np.asarray(info['angular_vel'])\n",
    "        acc = np.asarray(info['acceleration'])\n",
    "        steer = np.asarray(info['steer'])\n",
    "        next_state = np.concatenate((pos, ang, acc, steer), axis=None)\n",
    "        #update state\n",
    "        state = torch.tensor(next_state)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            print(reward)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bbf35be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
