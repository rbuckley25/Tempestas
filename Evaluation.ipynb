{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import torch\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "import carla\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import gym\n",
    "import gym_carla\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "connecting to Carla server...\n",
      "Carla server connected!\n",
      "WeatherParameters(cloudiness=5.000000, cloudiness=5.000000, precipitation=0.000000, precipitation_deposits=0.000000, wind_intensity=10.000000, sun_azimuth_angle=-1.000000, sun_altitude_angle=45.000000, fog_density=2.000000, fog_distance=0.750000, fog_falloff=0.100000, wetness=0.000000, scattering_intensity=1.000000, mie_scattering_scale=0.030000, rayleigh_scattering_scale=0.033100)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'number_of_vehicles': 3,\n",
    "    'number_of_walkers': 0,\n",
    "    'display_size': 256,  # screen size of bird-eye render\n",
    "    'max_past_step': 1,  # the number of past steps to draw\n",
    "    'dt': 0.1,  # time interval between two frames\n",
    "    'discrete': True,  # whether to use discrete control space\n",
    "    'discrete_acc': [2.0],  # discrete value of accelerations\n",
    "    'discrete_steer': [-0.3, 0.0, 0.3],  # discrete value of steering angles\n",
    "    'continuous_accel_range': [-3.0, 3.0],  # continuous acceleration range\n",
    "    'continuous_steer_range': [-0.3, 0.3],  # continuous steering angle range\n",
    "    'ego_vehicle_filter': 'vehicle.lincoln*',  # filter for defining ego vehicle\n",
    "    'port': 3000,  # connection port\n",
    "    'town': 'Town04',  # which town to simulate\n",
    "    'task_mode': 'random',  # mode of the task, [random, roundabout (only for Town03)]\n",
    "    'max_time_episode': 500,  # maximum timesteps per episode\n",
    "    'max_waypt': 12,  # maximum number of waypoints\n",
    "    'obs_range': 32,  # observation range (meter)\n",
    "    'lidar_bin': 0.125,  # bin size of lidar sensor (meter)\n",
    "    'd_behind': 12,  # distance behind the ego vehicle (meter)\n",
    "    'out_lane_thres': 1.8,  # threshold for out of lane\n",
    "    'desired_speed': 3,  # desired speed (m/s)\n",
    "    'max_ego_spawn_times': 20,  # maximum times to spawn ego vehicle\n",
    "    'display_route': True,  # whether to render the desired route\n",
    "    'pixor_size': 64,  # size of the pixor labels\n",
    "    'pixor': False,  # whether to output PIXOR observation\n",
    "    'use_fixed':True,\n",
    "    'weather':'ClearNoon',\n",
    "    'obs_size':128,\n",
    "    'routes':None,\n",
    "    'Collect_Data':False\n",
    "}\n",
    "\n",
    "# Set gym-carla environment\n",
    "env = gym.make('carla-v0', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def save_images(rgb,generated,step,folder):\n",
    "    im = Image.fromarray(rgb)\n",
    "    im.save('./Video/'+folder+'/RGB/'+str(step)+\".jpeg\")\n",
    "    generated.save('./Video/'+folder+'/Sem/'+str(step)+'.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepDQN(\n",
       "  (lin1): Linear(in_features=9, out_features=80, bias=True)\n",
       "  (lin2): Linear(in_features=80, out_features=50, bias=True)\n",
       "  (lin3): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (lin4): Linear(in_features=25, out_features=15, bias=True)\n",
       "  (lin5): Linear(in_features=15, out_features=8, bias=True)\n",
       "  (lin6): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_net = models.DeepDQN(3,device).to(device)\n",
    "vis_net.load_state_dict(torch.load('./model_params_CL/model_10.final'))\n",
    "vis_net.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waypoint Model\n",
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test routes 192, 193, 197, 371\n",
    "route = {'Town04':{'H':[192]}} \n",
    "env.routes = route\n",
    "env.routes_dict = route\n",
    "env.desired_speed = 5\n",
    "env.max_time_episode = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101. 100.   1.]]\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "env.use_fixed = 'H'\n",
    "env.route_idx = 1\n",
    "levels = ['E','M','H']\n",
    "next_lvl = 4\n",
    "min_overall_loss = 1000\n",
    "results = np.zeros((num_episodes,3))\n",
    "for i_episode in range(num_episodes):\n",
    "    rewards = 0\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    #ego_dir retirves the distance and angle from vehicle to nearest waypoint\n",
    "    ego_location = env.ego.get_location()\n",
    "    ego_dir = gym_carla.envs.misc.get_lane_dis(env.waypoints,ego_location.x,ego_location.y)\n",
    "    #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "    ego_pos = np.asarray((ego_dir[0],ego_dir[1][0],ego_dir[1][1]),dtype=np.float32)\n",
    "    state = np.concatenate((ego_pos,np.zeros(6)))\n",
    "    state = torch.tensor(state)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    loss = episode_loss = 1000\n",
    "    for t in count():\n",
    "        # Select and perform an actionii#\n",
    "        with torch.no_grad():\n",
    "            action = vis_net(state.float()).argmax().view(1,1)\n",
    "        obs, reward, done, info  = env.step(action.item())\n",
    "        sem_image = utils.replace(obs['semantic'][:,:,0])\n",
    "        env.show_images(sem_image)\n",
    "        save_images(obs['camera'],Image.fromarray(sem_image,'RGB'),t,'Waypoint')\n",
    "        rewards += reward\n",
    "        \n",
    "        #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "        pos = np.asarray((info['position'][0],info['position'][1][0],info['position'][1][1]))\n",
    "        ang = np.asarray(info['angular_vel'])\n",
    "        acc = np.asarray(info['acceleration'])\n",
    "        steer = np.asarray(info['steer'])\n",
    "        next_state = np.concatenate((pos, ang, acc, steer), axis=None)\n",
    "        #update state\n",
    "        state = torch.tensor(next_state)\n",
    "\n",
    "        if done:\n",
    "            results[i_episode,0] = rewards\n",
    "            results[i_episode,1] = t\n",
    "            if t  == env.max_time_episode:\n",
    "                results[i_episode,2] = 1\n",
    "            else:\n",
    "                results[i_episode,2] = 0\n",
    "            print(results)\n",
    "            print('########')\n",
    "            \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 13, 13, ...,  9,  9,  9],\n",
       "       [13, 13, 13, ...,  9,  9,  9],\n",
       "       [13, 13, 13, ...,  9,  9,  9],\n",
       "       ...,\n",
       "       [ 7,  7,  7, ...,  7,  7,  7],\n",
       "       [ 7,  7,  7, ...,  7,  7,  7],\n",
       "       [ 7,  7,  7, ...,  7,  7,  7]], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs['semantic'][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results,file):\n",
    "    data = pd.DataFrame(results,columns=['Reward','Length','Completed'])\n",
    "    data.to_csv(file)\n",
    "    return data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reward</th>\n",
       "      <th>Length</th>\n",
       "      <th>Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.007892</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.395705</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.326883</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.307476</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88.963381</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.951552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reward  Length  Completed\n",
       "0   99.007892   100.0        1.0\n",
       "1   99.395705   100.0        1.0\n",
       "2  101.000000   100.0        1.0\n",
       "3   98.326883   100.0        1.0\n",
       "4  101.000000   100.0        1.0\n",
       "5  100.307476   100.0        1.0\n",
       "6   88.963381   100.0        1.0\n",
       "7   93.951552   100.0        1.0\n",
       "8  101.000000   100.0        1.0\n",
       "9  101.000000   100.0        1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = save_results(results,'./model_results/SimpleModel/Clear/gentle_right.csv')\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceptionNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6a): Conv2d(512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv6b): Conv2d(512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv7): ConvTranspose2d(64, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): ConvTranspose2d(32, 13, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_net = models.Full_DQN(3,64,device).to(device)\n",
    "vis_net.load_state_dict(torch.load('./model_params_CL/Full_model_17.best'))\n",
    "vis_net.eval()\n",
    "\n",
    "model = models.PerceptionNet(device).to(device)\n",
    "model.load_state_dict(torch.load('./AE_params/model_46.best'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test routes 192, 193, 197, 371, 348\n",
    "route = {'Town04':{'H':[193]}} \n",
    "env.routes = route\n",
    "env.routes_dict = route\n",
    "env.desired_speed = 5\n",
    "env.max_time_episode = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101. 100.   1.]]\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "env.use_fixed = 'H'\n",
    "env.route_idx = 1\n",
    "levels = ['E','M','H']\n",
    "next_lvl = 4\n",
    "min_overall_loss = 1000\n",
    "input_size = 73\n",
    "results = np.zeros((num_episodes,3))\n",
    "for i_episode in range(num_episodes):\n",
    "    eps_loss = []\n",
    "    rewards = 0\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    ego_location = env.ego.get_location()\n",
    "    ego_dir = gym_carla.envs.misc.get_lane_dis(env.waypoints,ego_location.x,ego_location.y)\n",
    "    #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "    ego_pos = np.asarray((ego_dir[0],ego_dir[1][0],ego_dir[1][1]),dtype=np.float32)\n",
    "    state = np.concatenate((ego_pos,np.zeros(6)))\n",
    "    state = torch.tensor(state).reshape(1,9,1,1)\n",
    "\n",
    "    new_obs = torch.tensor(obs['camera'])\n",
    "    new_obs = new_obs.permute(2,0,1).reshape(1,3,128,128)\n",
    "    \n",
    "    _,latent_space = model(new_obs)\n",
    "    state = torch.cat((state,latent_space.cpu()),1).reshape(1,input_size)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    loss = episode_loss = 1000\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action = vis_net(state.float()).argmax().view(1,1)\n",
    "            obs, reward, done, info  = env.step(action.item())\n",
    "            sem_image = utils.generate_semantic_im(torch.tensor(obs['camera']).permute(2,0,1),model)\n",
    "            env.show_images(np.asarray(sem_image))\n",
    "            save_images(obs['camera'],sem_image,t,'Full')\n",
    "            new_obs = torch.tensor(obs['camera'])\n",
    "            new_obs = new_obs.permute(2,0,1).reshape(1,3,128,128)\n",
    "            _,latent_space = model(new_obs)\n",
    "            rewards += reward\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "\n",
    "            #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "            pos = np.asarray((info['position'][0],info['position'][1][0],info['position'][1][1]))\n",
    "            ang = np.asarray(info['angular_vel'])\n",
    "            acc = np.asarray(info['acceleration'])\n",
    "            steer = np.asarray(info['steer'])\n",
    "            next_state = np.concatenate((pos, ang, acc, steer), axis=None)\n",
    "            \n",
    "            \n",
    "            info_state = torch.tensor(next_state).reshape(1,9,1,1)\n",
    "            next_state = torch.cat((info_state,latent_space.cpu()),1).reshape(1,input_size)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            results[i_episode,0] = rewards\n",
    "            results[i_episode,1] = t\n",
    "            if t  == env.max_time_episode:\n",
    "                results[i_episode,2] = 1\n",
    "            else:\n",
    "                results[i_episode,2] = 0\n",
    "            print(results)\n",
    "            print('########')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reward</th>\n",
       "      <th>Length</th>\n",
       "      <th>Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reward  Length  Completed\n",
       "0   101.0   100.0        1.0\n",
       "1   101.0   100.0        1.0\n",
       "2   101.0   100.0        1.0\n",
       "3   101.0   100.0        1.0\n",
       "4   101.0   100.0        1.0\n",
       "5   101.0   100.0        1.0\n",
       "6   101.0   100.0        1.0\n",
       "7   101.0   100.0        1.0\n",
       "8   101.0   100.0        1.0\n",
       "9   101.0   100.0        1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = save_results(results,'./model_results/FullModel/Clear/right_turn.csv')\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63f12c6fbc5857ff15291fb417d86d25a665886c9e9c67e60a616b8bb414d7e7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
