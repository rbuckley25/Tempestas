{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import torch\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "import carla\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import gym\n",
    "import gym_carla\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpb3/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/rpb3/anaconda3/envs/pytorch/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to Carla server...\n",
      "Carla server connected!\n",
      "WeatherParameters(cloudiness=5.000000, cloudiness=5.000000, precipitation=0.000000, precipitation_deposits=0.000000, wind_intensity=10.000000, sun_azimuth_angle=-1.000000, sun_altitude_angle=45.000000, fog_density=2.000000, fog_distance=0.750000, fog_falloff=0.100000, wetness=0.000000, scattering_intensity=1.000000, mie_scattering_scale=0.030000, rayleigh_scattering_scale=0.033100)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'number_of_vehicles': 3,\n",
    "    'number_of_walkers': 0,\n",
    "    'display_size': 256,  # screen size of bird-eye render\n",
    "    'max_past_step': 1,  # the number of past steps to draw\n",
    "    'dt': 0.1,  # time interval between two frames\n",
    "    'discrete': True,  # whether to use discrete control space\n",
    "    'discrete_acc': [2.0],  # discrete value of accelerations\n",
    "    'discrete_steer': [-0.3, 0.0, 0.3],  # discrete value of steering angles\n",
    "    'continuous_accel_range': [-3.0, 3.0],  # continuous acceleration range\n",
    "    'continuous_steer_range': [-0.3, 0.3],  # continuous steering angle range\n",
    "    'ego_vehicle_filter': 'vehicle.lincoln*',  # filter for defining ego vehicle\n",
    "    'port': 2000,  # connection port\n",
    "    'town': 'Town04',  # which town to simulate\n",
    "    'task_mode': 'random',  # mode of the task, [random, roundabout (only for Town03)]\n",
    "    'max_time_episode': 500,  # maximum timesteps per episode\n",
    "    'max_waypt': 12,  # maximum number of waypoints\n",
    "    'obs_range': 32,  # observation range (meter)\n",
    "    'lidar_bin': 0.125,  # bin size of lidar sensor (meter)\n",
    "    'd_behind': 12,  # distance behind the ego vehicle (meter)\n",
    "    'out_lane_thres': 4,  # threshold for out of lane\n",
    "    'desired_speed': 5,  # desired speed (m/s)\n",
    "    'max_ego_spawn_times': 20,  # maximum times to spawn ego vehicle\n",
    "    'display_route': True,  # whether to render the desired route\n",
    "    'pixor_size': 64,  # size of the pixor labels\n",
    "    'pixor': False,  # whether to output PIXOR observation\n",
    "    'use_fixed':True,\n",
    "    'weather':'ClearNoon',\n",
    "    'obs_size':128,\n",
    "    'routes':None,\n",
    "    'Collect_Data':False\n",
    "}\n",
    "\n",
    "# Set gym-carla environment\n",
    "env = gym.make('carla-v0', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def save_images(rgb,generated,step,folder):\n",
    "    im = Image.fromarray(rgb)\n",
    "    im.save('./Video/'+folder+'/RGB/'+str(step)+\".jpeg\")\n",
    "    generated.save('./Video/'+folder+'/Sem/'+str(step)+'.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepDQN(\n",
       "  (lin1): Linear(in_features=9, out_features=80, bias=True)\n",
       "  (lin2): Linear(in_features=80, out_features=50, bias=True)\n",
       "  (lin3): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (lin4): Linear(in_features=25, out_features=15, bias=True)\n",
       "  (lin5): Linear(in_features=15, out_features=8, bias=True)\n",
       "  (lin6): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_net = models.DeepDQN(3,device).to(device)\n",
    "vis_net.load_state_dict(torch.load('./model_params_CL/model_10.final'))\n",
    "vis_net.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waypoint Model\n",
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test routes 192, 193, 197, 371, 250\n",
    "route = {'Town04':{'H':[250]}} \n",
    "env.routes = route\n",
    "env.routes_dict = route\n",
    "env.desired_speed = 5\n",
    "env.max_time_episode = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [  0.   0.   0.]]\n",
      "########\n",
      "[[101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]\n",
      " [101. 100.   1.]]\n",
      "########\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "env.use_fixed = 'H'\n",
    "env.route_idx = 1\n",
    "levels = ['E','M','H']\n",
    "next_lvl = 4\n",
    "min_overall_loss = 1000\n",
    "results = np.zeros((num_episodes,3))\n",
    "for i_episode in range(num_episodes):\n",
    "    rewards = 0\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    #ego_dir retirves the distance and angle from vehicle to nearest waypoint\n",
    "    ego_location = env.ego.get_location()\n",
    "    ego_dir = gym_carla.envs.misc.get_lane_dis(env.waypoints,ego_location.x,ego_location.y)\n",
    "    #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "    ego_pos = np.asarray((ego_dir[0][0],ego_dir[0][1][0],ego_dir[0][1][1]),dtype=np.float32)\n",
    "    state = np.concatenate((ego_pos,np.zeros(6)))\n",
    "    state = torch.tensor(state)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    loss = episode_loss = 1000\n",
    "    for t in count():\n",
    "        # Select and perform an actionii#\n",
    "        with torch.no_grad():\n",
    "            action = vis_net(state.float()).argmax().view(1,1)\n",
    "        obs, reward, done, info  = env.step(action.item())\n",
    "        sem_image = utils.replace(obs['semantic'][:,:,0])\n",
    "        env.show_images(sem_image)\n",
    "        #save_images(obs['camera'],Image.fromarray(sem_image,'RGB'),t,'Waypoint')\n",
    "        rewards += reward\n",
    "        \n",
    "        #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "        pos = np.asarray((info['position'][0],info['position'][1][0],info['position'][1][1]))\n",
    "        ang = np.asarray(info['angular_vel'])\n",
    "        acc = np.asarray(info['acceleration'])\n",
    "        steer = np.asarray(info['steer'])\n",
    "        next_state = np.concatenate((pos, ang, acc, steer), axis=None)\n",
    "        #update state\n",
    "        state = torch.tensor(next_state)\n",
    "\n",
    "        if done:\n",
    "            results[i_episode,0] = rewards\n",
    "            results[i_episode,1] = t\n",
    "            if t  == env.max_time_episode:\n",
    "                results[i_episode,2] = 1\n",
    "            else:\n",
    "                results[i_episode,2] = 0\n",
    "            print(results)\n",
    "            print('########')\n",
    "            \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results,file):\n",
    "    data = pd.DataFrame(results,columns=['Reward','Length','Completed'])\n",
    "    data.to_csv(file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reward</th>\n",
       "      <th>Length</th>\n",
       "      <th>Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reward  Length  Completed\n",
       "0   101.0   100.0        1.0\n",
       "1   101.0   100.0        1.0\n",
       "2   101.0   100.0        1.0\n",
       "3   101.0   100.0        1.0\n",
       "4   101.0   100.0        1.0\n",
       "5   101.0   100.0        1.0\n",
       "6   101.0   100.0        1.0\n",
       "7   101.0   100.0        1.0\n",
       "8   101.0   100.0        1.0\n",
       "9   101.0   100.0        1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = save_results(results,'./streamlit/model_results/SimpleModel/Clear/gentle_left.csv')\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceptionNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6a): Conv2d(512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv6b): Conv2d(512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv7): ConvTranspose2d(64, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): ConvTranspose2d(32, 13, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_net = models.Full_DQN(3,64,device).to(device)\n",
    "#14 is left turn, 15 is rigth turn\n",
    "vis_net.load_state_dict(torch.load('./model_params_CL/Full_model_18.best'))\n",
    "vis_net.eval()\n",
    "\n",
    "\n",
    "\n",
    "model = models.PerceptionNet(device).to(device)\n",
    "model.load_state_dict(torch.load('./AE_params/model_46.best'))\n",
    "model.eval()\n",
    "\n",
    "base_model = models.PerceptionNet(device).to(device)\n",
    "base_model.load_state_dict(torch.load('./AE_params/model_46.best'))\n",
    "base_model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test routes 192, 193, 197, 371, 250\n",
    "route = {'Town04':{'H':[250]}} \n",
    "env.routes = route\n",
    "env.routes_dict = route\n",
    "env.desired_speed = 5\n",
    "env.max_time_episode = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51. 71.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "########\n",
      "[[51. 71.  0.]\n",
      " [53. 73.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30324/1512211910.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvis_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'camera'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Carla/gym-carla/gym_carla/envs/carla_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Carla/gym-carla/gym_carla/envs/carla_env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_route\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       \u001b[0mbirdeye_render_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'waypoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbirdeye_render\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbirdeye_render_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0mbirdeye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurfarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mbirdeye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbirdeye\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Carla/gym-carla/gym_carla/envs/render.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, display, render_types)\u001b[0m\n\u001b[1;32m    534\u001b[0m       self.walker_polygons)\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaypoints_surface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLOR_BLACK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m     self.render_waypoints(\n\u001b[1;32m    538\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaypoints_surface\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "env.use_fixed = 'H'\n",
    "env.route_idx = 1\n",
    "levels = ['E','M','H']\n",
    "next_lvl = 4\n",
    "min_overall_loss = 1000\n",
    "input_size = 73\n",
    "results = np.zeros((num_episodes,3))\n",
    "for i_episode in range(num_episodes):\n",
    "    eps_loss = []\n",
    "    rewards = 0\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    ego_location = env.ego.get_location()\n",
    "    ego_dir = gym_carla.envs.misc.get_lane_dis(env.waypoints,ego_location.x,ego_location.y)\n",
    "    #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "    ego_pos = np.asarray((ego_dir[0][0],ego_dir[0][1][0],ego_dir[0][1][1]),dtype=np.float32)\n",
    "    state = np.concatenate((ego_pos,np.zeros(6)))\n",
    "    state = torch.tensor(state).reshape(1,9,1,1)\n",
    "\n",
    "    new_obs = torch.tensor(obs['camera'])\n",
    "    new_obs = new_obs.permute(2,0,1).reshape(1,3,128,128)\n",
    "    \n",
    "    _,latent_space = model(new_obs)\n",
    "    state = torch.cat((state,latent_space.cpu()),1).reshape(1,input_size)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    loss = episode_loss = 1000\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action = vis_net(state.float()).argmax().view(1,1)\n",
    "            obs, reward, done, info  = env.step(action.item())\n",
    "\n",
    "            new_obs = torch.tensor(obs['camera'])\n",
    "            new_obs = new_obs.permute(2,0,1).reshape(1,3,128,128)\n",
    "            _,latent_space = model(new_obs)\n",
    "\n",
    "            sem = base_model.decode(latent_space).detach().cpu().argmax(dim=1)\n",
    "            sem = utils.replace(sem.numpy().reshape(1,128,128).transpose(1,2,0))\n",
    "            env.show_images(sem)\n",
    "\n",
    "            #save_images(obs['camera'],Image.fromarray(sem,'RGB'),t,'Full/Wet/Cloudy')\n",
    "\n",
    "            rewards += reward\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "\n",
    "            #pos gets a distanc d and array w which has to be seperated out in below line\n",
    "            pos = np.asarray((info['position'][0],info['position'][1][0],info['position'][1][1]))\n",
    "            ang = np.asarray(info['angular_vel'])\n",
    "            acc = np.asarray(info['acceleration'])\n",
    "            steer = np.asarray(info['steer'])\n",
    "            next_state = np.concatenate((pos, ang, acc, steer), axis=None)\n",
    "            \n",
    "            \n",
    "            info_state = torch.tensor(next_state).reshape(1,9,1,1)\n",
    "            next_state = torch.cat((info_state,latent_space.cpu()),1).reshape(1,input_size)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            results[i_episode,0] = rewards\n",
    "            results[i_episode,1] = t\n",
    "            if t  == env.max_time_episode:\n",
    "                results[i_episode,2] = 1\n",
    "            else:\n",
    "                results[i_episode,2] = 0\n",
    "            print(results)\n",
    "            print('########')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reward</th>\n",
       "      <th>Length</th>\n",
       "      <th>Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.107342</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Reward  Length  Completed\n",
       "0  11.107342    35.0        0.0\n",
       "1  14.000000    34.0        0.0\n",
       "2  15.000000    35.0        0.0\n",
       "3  14.000000    34.0        0.0\n",
       "4  15.000000    35.0        0.0\n",
       "5  14.000000    34.0        0.0\n",
       "6  15.000000    35.0        0.0\n",
       "7  13.000000    33.0        0.0\n",
       "8  14.000000    34.0        0.0\n",
       "9  16.000000    36.0        0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = save_results(results,'./streamlit/model_results/FullModel/Clear/slight_left.csv')\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63f12c6fbc5857ff15291fb417d86d25a665886c9e9c67e60a616b8bb414d7e7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
